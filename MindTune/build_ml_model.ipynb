{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 26,
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 31,
   "source": "from sklearn.metrics import classification_report",
   "id": "1cf6733d7d461020"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 2,
   "source": [
    "class CustomCSVDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the data subdirectories.\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for label, folder_name in enumerate(['0', '1']):\n",
    "            folder_path = os.path.join(root_dir, folder_name)\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith('.csv'):\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    csv_data = pd.read_csv(file_path)\n",
    "                    csv_data = csv_data.drop('label', axis=1)\n",
    "                    csv_data = csv_data.values\n",
    "                    self.data.append(torch.tensor(csv_data, dtype=torch.float32))\n",
    "                    self.labels.append(label)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ],
   "id": "cb7e6c8f62cca462"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 2)  # Assuming binary classification (2 classes)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "id": "1195da408a6ad133"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 21,
   "source": [
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_heads=2, num_layers=1):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_size, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size, 2)  # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = x.unsqueeze(0)  # Add batch dimension for transformer input\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.squeeze(0)  # Remove batch dimension\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "id": "92486e9dbd2d637"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 4,
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.view(inputs.size(0), -1), labels  # Flatten inputs if necessary\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    " "
   ],
   "id": "96cfeef2f15d7a4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 5,
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.view(inputs.size(0), -1), labels\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy: {100 * correct / total:.2f}%')"
   ],
   "id": "79d79f9b143b9c96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:41:13.134402Z",
     "start_time": "2025-03-15T10:41:13.125403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.view(inputs.size(0), -1), labels\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_predictions.extend(predicted.numpy())\n",
    "    # Generate and print the classification report\n",
    "    print(classification_report(all_labels, all_predictions, target_names=['Class 0', 'Class 1']))"
   ],
   "id": "14b0b72b27af999a",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 14,
   "source": [
    "root_dir = 'dataset_postprocessing'  # Update with your data path\n",
    "input_size = 64  # Replace with the actual number of features in your data\n",
    "dataset = CustomCSVDataset(root_dir)\n",
    "train_loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(dataset, batch_size=2, shuffle=False)"
   ],
   "id": "1ff0bfc56033390f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:55:32.527822Z",
     "start_time": "2025-03-15T10:55:32.520821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SimpleClassifier(input_size=input_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "308ce730179eef40",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:55:35.518327Z",
     "start_time": "2025-03-15T10:55:35.500321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_transformer = TransformerClassifier(input_size=input_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_transformer.parameters(), lr=0.001)"
   ],
   "id": "fe1d7cc59a8bac89",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:55:47.918710Z",
     "start_time": "2025-03-15T10:55:47.784747Z"
    }
   },
   "cell_type": "code",
   "source": "train_model(model, train_loader, criterion, optimizer, num_epochs=20)",
   "id": "583549340ccea2f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.6578\n",
      "Epoch [2/20], Loss: 0.2210\n",
      "Epoch [3/20], Loss: 0.7951\n",
      "Epoch [4/20], Loss: 0.2753\n",
      "Epoch [5/20], Loss: 1.0259\n",
      "Epoch [6/20], Loss: 5.7062\n",
      "Epoch [7/20], Loss: 0.7935\n",
      "Epoch [8/20], Loss: 5.9031\n",
      "Epoch [9/20], Loss: 3.5541\n",
      "Epoch [10/20], Loss: 0.0002\n",
      "Epoch [11/20], Loss: 0.7089\n",
      "Epoch [12/20], Loss: 5.6380\n",
      "Epoch [13/20], Loss: 0.7832\n",
      "Epoch [14/20], Loss: 1.7740\n",
      "Epoch [15/20], Loss: 3.2357\n",
      "Epoch [16/20], Loss: 0.1044\n",
      "Epoch [17/20], Loss: 0.0249\n",
      "Epoch [18/20], Loss: 1.0187\n",
      "Epoch [19/20], Loss: 5.0686\n",
      "Epoch [20/20], Loss: 0.0320\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:55:54.418203Z",
     "start_time": "2025-03-15T10:55:53.168962Z"
    }
   },
   "cell_type": "code",
   "source": "train_model(model_transformer, train_loader, criterion, optimizer, num_epochs=20)",
   "id": "50b7ec41f8bf1e69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.4593\n",
      "Epoch [2/20], Loss: 0.0966\n",
      "Epoch [3/20], Loss: 0.0179\n",
      "Epoch [4/20], Loss: 0.1933\n",
      "Epoch [5/20], Loss: 0.0157\n",
      "Epoch [6/20], Loss: 0.0153\n",
      "Epoch [7/20], Loss: 0.0079\n",
      "Epoch [8/20], Loss: 0.0069\n",
      "Epoch [9/20], Loss: 0.2230\n",
      "Epoch [10/20], Loss: 0.1131\n",
      "Epoch [11/20], Loss: 0.0109\n",
      "Epoch [12/20], Loss: 0.0071\n",
      "Epoch [13/20], Loss: 0.1959\n",
      "Epoch [14/20], Loss: 0.0101\n",
      "Epoch [15/20], Loss: 0.0070\n",
      "Epoch [16/20], Loss: 0.0076\n",
      "Epoch [17/20], Loss: 0.3940\n",
      "Epoch [18/20], Loss: 0.1287\n",
      "Epoch [19/20], Loss: 0.0060\n",
      "Epoch [20/20], Loss: 0.3424\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:55:59.756374Z",
     "start_time": "2025-03-15T10:55:59.721436Z"
    }
   },
   "cell_type": "code",
   "source": "evaluate_model(model_transformer, train_loader)",
   "id": "5a680fd604044e61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      0.95      0.97        37\n",
      "     Class 1       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.96        52\n",
      "   macro avg       0.94      0.97      0.95        52\n",
      "weighted avg       0.97      0.96      0.96        52\n",
      "\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:41:14.689520Z",
     "start_time": "2025-03-15T10:41:14.677519Z"
    }
   },
   "cell_type": "code",
   "source": "evaluate_model(model, test_loader)",
   "id": "ac0a67517d32ece8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.93      1.00      0.96        37\n",
      "     Class 1       1.00      0.80      0.89        15\n",
      "\n",
      "    accuracy                           0.94        52\n",
      "   macro avg       0.96      0.90      0.92        52\n",
      "weighted avg       0.95      0.94      0.94        52\n",
      "\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c427097493471cd0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
